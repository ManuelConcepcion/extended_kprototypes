{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Experiments for Extended K-Prototypes (Paper Versions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variations on the experimental structure of the original extension as presented for the undergraduate thesis of the author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the absolute path of the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from random import randint\n",
    "from typing import Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from benchmark_extension import Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data generation has been changed to follow a probabilistic approach for the generation of the categorical and multi-valued attributes.  \n",
    "  \n",
    "Categorical attributes are sampled from a user-defined distribution of categorical items.  \n",
    "  \n",
    "Multi-valued attributes are sampled using a tree of conditional probability per cluster to simulate the way in which some items of multi-valued attributes tend to appear in common with others. This is preferred to repeating the approach pursued for categorical variables to better represent real-life conditions that practitioners may face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_configuration = {\n",
    "    'n_samples': 2000,\n",
    "    'n_clusters': 3,\n",
    "    'class_weights': [0.33, 0.33],\n",
    "    # Numeric Features\n",
    "    'n_numeric_features': 5,\n",
    "    'separability': 3.0,\n",
    "    'noise': 0.01,\n",
    "    # Categroical Features\n",
    "    'n_categorical_features': 5,\n",
    "    'categorical_cardinalities': [6, 6, 6, 6, 6],\n",
    "    'category_distributions':(  # One list per feature per cluster\n",
    "        [\n",
    "            [0.4, 0.4, 0.05, 0.05, 0.05],\n",
    "            [0.4, 0.4, 0.05, 0.05, 0.05],\n",
    "            [0.4, 0.4, 0.05, 0.05, 0.05],\n",
    "            [0.4, 0.4, 0.05, 0.05, 0.05],\n",
    "            [0.4, 0.4, 0.05, 0.05, 0.05]],\n",
    "        [\n",
    "            [0.05, 0.05, 0.4, 0.4, 0.05],\n",
    "            [0.05, 0.05, 0.4, 0.4, 0.05],\n",
    "            [0.05, 0.05, 0.4, 0.4, 0.05],\n",
    "            [0.05, 0.05, 0.4, 0.4, 0.05],\n",
    "            [0.05, 0.05, 0.4, 0.4, 0.05]],\n",
    "        [\n",
    "            [0.05, 0.05, 0.05, 0.05, 0.4],\n",
    "            [0.05, 0.05, 0.05, 0.05, 0.4],\n",
    "            [0.05, 0.05, 0.05, 0.05, 0.4],\n",
    "            [0.05, 0.05, 0.05, 0.05, 0.4],\n",
    "            [0.05, 0.05, 0.05, 0.05, 0.4]]\n",
    "    ),\n",
    "    # Multi-valued Features\n",
    "    'n_multival_features': 5,\n",
    "    'base_chances': (   # One list per feature per cluster\n",
    "        [   \n",
    "            [0.4, 0.4, 0.05, 0.05, 0.05],\n",
    "            [0.4, 0.4, 0.05, 0.05, 0.05],\n",
    "            [0.4, 0.4, 0.05, 0.05, 0.05],\n",
    "            [0.4, 0.4, 0.05, 0.05, 0.05],\n",
    "            [0.4, 0.4, 0.05, 0.05, 0.05]\n",
    "        ],\n",
    "        [\n",
    "            [0.05, 0.05, 0.4, 0.4, 0.05],\n",
    "            [0.05, 0.05, 0.4, 0.4, 0.05],\n",
    "            [0.05, 0.05, 0.4, 0.4, 0.05],\n",
    "            [0.05, 0.05, 0.4, 0.4, 0.05],\n",
    "            [0.05, 0.05, 0.4, 0.4, 0.05]\n",
    "        ],\n",
    "        [\n",
    "            [0.05, 0.05, 0.05, 0.05, 0.4],\n",
    "            [0.05, 0.05, 0.05, 0.05, 0.4],\n",
    "            [0.05, 0.05, 0.05, 0.05, 0.4],\n",
    "            [0.05, 0.05, 0.05, 0.05, 0.4],\n",
    "            [0.05, 0.05, 0.05, 0.05, 0.4]\n",
    "        ]\n",
    "    ),\n",
    "    'conditional_probabilities': (\n",
    "        [  # One dict per feature, per cluster\n",
    "            {\n",
    "                0: [0.04, 0.80, 0.04, 0.04, 0.04],\n",
    "                1: [0.80, 0.04, 0.04, 0.04, 0.04]\n",
    "            },\n",
    "            {\n",
    "                0: [0.04, 0.80, 0.04, 0.04, 0.04],\n",
    "                1: [0.80, 0.04, 0.04, 0.04, 0.04]\n",
    "            },\n",
    "            {\n",
    "                0: [0.04, 0.80, 0.04, 0.04, 0.04],\n",
    "                1: [0.80, 0.04, 0.04, 0.04, 0.04]\n",
    "            },\n",
    "            {\n",
    "                0: [0.04, 0.80, 0.04, 0.04, 0.04],\n",
    "                1: [0.80, 0.04, 0.04, 0.04, 0.04]\n",
    "            },\n",
    "            {\n",
    "                0: [0.04, 0.80, 0.04, 0.04, 0.04],\n",
    "                1: [0.80, 0.04, 0.04, 0.04, 0.04]\n",
    "            }],\n",
    "        [\n",
    "            {\n",
    "                2: [0.04, 0.04, 0.04, 0.80, 0.04],\n",
    "                3: [0.04, 0.04, 0.80, 0.04, 0.04],\n",
    "            },\n",
    "            {\n",
    "                2: [0.04, 0.04, 0.04, 0.80, 0.04],\n",
    "                3: [0.04, 0.04, 0.80, 0.04, 0.04],\n",
    "            },\n",
    "            {\n",
    "                2: [0.04, 0.04, 0.04, 0.80, 0.04],\n",
    "                3: [0.04, 0.04, 0.80, 0.04, 0.04],\n",
    "            },\n",
    "            {\n",
    "                2: [0.04, 0.04, 0.04, 0.80, 0.04],\n",
    "                3: [0.04, 0.04, 0.80, 0.04, 0.04],\n",
    "            },\n",
    "            {\n",
    "                2: [0.04, 0.04, 0.04, 0.80, 0.04],\n",
    "                3: [0.04, 0.04, 0.80, 0.04, 0.04],\n",
    "            }],\n",
    "        [\n",
    "            {\n",
    "                4: [0.04, 0.04, 0.04, 0.04, 0.04],\n",
    "                5: [0.04, 0.04, 0.04, 0.04, 0.80]\n",
    "            },\n",
    "            {\n",
    "                4: [0.04, 0.04, 0.04, 0.04, 0.04],\n",
    "                5: [0.04, 0.04, 0.04, 0.04, 0.80]\n",
    "            },\n",
    "            {\n",
    "                4: [0.04, 0.04, 0.04, 0.04, 0.04],\n",
    "                5: [0.04, 0.04, 0.04, 0.04, 0.80]\n",
    "            },\n",
    "            {\n",
    "                4: [0.04, 0.04, 0.04, 0.04, 0.04],\n",
    "                5: [0.04, 0.04, 0.04, 0.04, 0.80]\n",
    "            },\n",
    "            {\n",
    "                4: [0.04, 0.04, 0.04, 0.04, 0.04],\n",
    "                5: [0.04, 0.04, 0.04, 0.04, 0.80]\n",
    "            }]\n",
    "    ),\n",
    "    # Approach Settings\n",
    "    'approach_settings': {\n",
    "        'naive': {\n",
    "            'gamma': None\n",
    "        },\n",
    "        'one-hot': {\n",
    "            'gamma': None,\n",
    "            'max_dummies': 100\n",
    "        },\n",
    "        'one-hot-pca': {\n",
    "            'gamma': None,\n",
    "            'reduced_dimensions': 0.25\n",
    "        },\n",
    "        'extended': {\n",
    "            'gamma_c': 0.33,\n",
    "            'gamma_m': 0.33,\n",
    "            'theta': 0.001\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample configuration includes a bi-modal distribution for each categorical attribute that modifies the modes for each cluster. Harder-to-cluster configurations where some elements are modal in more than one cluster or where some levels are never modal could be tried."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input Rules**:  \n",
    "\n",
    "- Class weights should be of length `n_clusters - 1`. The missing weight will be calculated with `1 - sum(class_weights)`.\n",
    "\n",
    "- Length of `categorical_cardinalities` equal to `n_categorical_features`.\n",
    "\n",
    "- Length of `category_distributions` should be equal to `n_clusters`. Each item is a list of lists specifying a categorical distribution for each categorical attribute describing the categorical characteristics of the cluster.\n",
    "  \n",
    "- Each item in `category_distributions` should include a list per categorical attribute containing the sampling probabilities for each category (as defined in `categorical_cardinalities` minus one) in the attribute. The probabilities should sum up to less than one. The probability for the missing category will be calculated as `1 - sum(distribution)`.\n",
    "  \n",
    "- Length of `probability_trees` should be equal to `n_multival_features`.\n",
    "  \n",
    "- The probabilities of the children of each node in each ``tree`` of ``probability_trees`` should sum up to one. Rule does not apply to leafs.\n",
    "  \n",
    "- In `approach_settings`, the field `reduced_dimensions` in `one-hot-pca` must be a float in the open interval $(0, 1)$.\n",
    "  \n",
    "- In `approach_settings`, the field the gamma fields in `extended` must be floats in the interval $[0, 1)$ and not sum up to more than one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_distributions_to_generation(cluster_assignment_vector: np.ndarray[int],\n",
    "                                    category_distributions: tuple[list[list[float]]],\n",
    "                                    n_categorical_features: int,\n",
    "                                    categorical_cardinalities: list[int],\n",
    "                                    n_clusters: int,\n",
    "                                    random_generator: np.random.Generator,\n",
    "                                    round_digits: int = 5):\n",
    "\n",
    "    # The expected structure of category distributions is\n",
    "    # tuple (len n_clusters)[list(len n_categorical_features)[list(categorical_cardinality - 1)]]\n",
    "    # A tuple containing matrices of shape (n_cat_features x (cardinality - 1)) ONLY IF THE CARDINALITY IS CONSTANT. \n",
    "    # Alternatively, it is a list of lists defining probabilities\n",
    "\n",
    "    # Checks that everything should be the way it is\n",
    "    if len(categorical_cardinalities) != n_categorical_features:\n",
    "        raise ValueError(f\"Mismatched categorical cardinalities ({len(categorical_cardinalities)}) and number of categorical features ({n_categorical_features})\")\n",
    "\n",
    "    if len(category_distributions) != n_clusters:\n",
    "        raise ValueError(f\"Mismatched distributions ({len(category_distributions)}) and clusters ({n_clusters})\")\n",
    "    \n",
    "    for distr in category_distributions:\n",
    "        if len(distr) != n_categorical_features:\n",
    "            raise ValueError(\"Probability distributions must be provided for all\"\n",
    "                             f\"categorical features ({n_categorical_features}).\"\n",
    "                             f\"Only {len(distr)} have been specified.\")\n",
    "        \n",
    "        for i, var_distr in enumerate(distr):\n",
    "            if len(var_distr) != (categorical_cardinalities[i]-1):\n",
    "                raise ValueError(\"Probability distribution must include categorical_cardinalities - 1 values.\")\n",
    "            if round(sum(var_distr), round_digits) > 1:\n",
    "                raise ValueError(\"Probability distribution must not sum up to more than one.\")\n",
    "    \n",
    "    # Code\n",
    "    output_columns = []\n",
    "\n",
    "    for i_feature in range(n_categorical_features):\n",
    "        # Check the cluster and get the respective prob distribution\n",
    "        # Sample once from the multinomial and use argmax to get the category\n",
    "        choice_func = np.vectorize(\n",
    "            lambda i_cluster:\n",
    "            np.argmax(\n",
    "                random_generator.multinomial(1,\n",
    "                    pvals=category_distributions[i_cluster][i_feature]+\\\n",
    "                            [np.round(1-sum(\n",
    "                                category_distributions[i_cluster][i_feature]\n",
    "                                ),\n",
    "                            round_digits)],\n",
    "                    size=1),\n",
    "                axis=1)\n",
    "        )\n",
    "        \n",
    "        output_columns.append(choice_func(cluster_assignment_vector))\n",
    "\n",
    "    cat_df = pd.DataFrame(np.array(output_columns).T)\n",
    "\n",
    "    colnames = []\n",
    "    for col in cat_df.columns:\n",
    "        colnames.append(f\"cat_{col}\")\n",
    "    \n",
    "    cat_df.columns = colnames\n",
    "\n",
    "    return cat_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_array = np.array([0, 1, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_0</th>\n",
       "      <th>cat_1</th>\n",
       "      <th>cat_2</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>cat_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cat_0  cat_1  cat_2  cat_3  cat_4\n",
       "0       5      0      1      1      4\n",
       "1       3      2      3      3      3\n",
       "2       2      2      2      3      0\n",
       "3       4      5      4      5      5\n",
       "4       2      3      2      1      2\n",
       "5       2      1      0      4      1\n",
       "6       0      0      0      0      0\n",
       "7       1      1      2      1      5\n",
       "8       1      0      0      1      1\n",
       "9       0      0      1      1      5\n",
       "10      0      1      4      2      0\n",
       "11      0      1      1      1      1\n",
       "12      1      1      0      5      1\n",
       "13      1      4      0      0      5\n",
       "14      1      1      0      5      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_distributions_to_generation(cluster_assignment_vector=cluster_array,\n",
    "                                category_distributions=sample_configuration['category_distributions'],\n",
    "                                n_categorical_features=sample_configuration['n_categorical_features'],\n",
    "                                categorical_cardinalities=sample_configuration['categorical_cardinalities'],\n",
    "                                n_clusters=sample_configuration['n_clusters'],\n",
    "                                random_generator=np.random.default_rng(42))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the multi-valued attributes, as generated from probability trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "base_chance = [0.05, 0.05, 0.4, 0.4, 0.05]\n",
    "\n",
    "conditional_probabilities = defaultdict(lambda: base_chance+[round(1-sum(base_chance))])\n",
    "\n",
    "specified_conditional_probabilities = {\n",
    "    2: [0.04, 0.04, 0.04, 0.80, 0.04],\n",
    "    3: [0.04, 0.04, 0.80, 0.04, 0.04]\n",
    "}\n",
    "\n",
    "conditional_probabilities.update(specified_conditional_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05, 0.05, 0.4, 0.4, 0.05, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_probabilities[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04, 0.04, 0.04, 0.8, 0.04]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_probabilities[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_multival_once(iterations: int,\n",
    "                         base_chance: list[float],\n",
    "                         conditional_probabilities: dict,\n",
    "                         random_generator: np.random.Generator):\n",
    "    choice = np.argmax(\n",
    "        random_generator.multinomial(1,\n",
    "            pvals=base_chance+[round(1-sum(base_chance))]\n",
    "        )\n",
    "    )\n",
    "    choice_set = {choice}\n",
    "\n",
    "    for i in range(iterations):\n",
    "        # Will get the base chance or the specified ones\n",
    "        choice = np.argmax(\n",
    "            random_generator.multinomial(1,\n",
    "                pvals=conditional_probabilities[choice]+[\n",
    "                    round(1-sum(conditional_probabilities[choice]))\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        choice_set.add(choice)\n",
    "\n",
    "    return choice_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_multival_once(iterations=10,\n",
    "                     base_chance=base_chance,\n",
    "                     conditional_probabilities=conditional_probabilities,\n",
    "                     random_generator=np.random.default_rng(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_lambda(val):\n",
    "    return lambda: val\n",
    "# We trick python by defining a new scope over the lambda,\n",
    "# such that the p array will be stored instead of pointing to the base_chance\n",
    "# variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multival_generation(cluster_assignment_vector: np.ndarray,\n",
    "                        n_clusters: int,\n",
    "                        n_multival_features: int,\n",
    "                        base_chances: list[list[float]],\n",
    "                        conditional_probabilities: list[dict],\n",
    "                        iterations: int,\n",
    "                        random_generator: np.random.Generator):\n",
    "    # Check input integrity\n",
    "    if len(base_chances) != n_clusters:\n",
    "        pass\n",
    "\n",
    "    # Cache the p-dicts here for the function call below\n",
    "    cluster_p_dicts = []\n",
    "    for i_cluster in range(n_clusters):\n",
    "        feature_dicts = []\n",
    "        \n",
    "        for i_feature in range(n_multival_features):\n",
    "            base_chance = deepcopy(\n",
    "                base_chances[i_cluster][i_feature]+[round(\n",
    "                    1-sum(base_chances[i_cluster][i_feature]))\n",
    "                ])\n",
    "            p_dict = defaultdict(fixed_lambda(base_chance))\n",
    "            \n",
    "            p_dict.update(conditional_probabilities[i_cluster][i_feature])\n",
    "            feature_dicts.append(p_dict)\n",
    "        \n",
    "        cluster_p_dicts.append(feature_dicts)\n",
    "    \n",
    "    # Vectorize the sampling function to create the features\n",
    "    output_columns = []\n",
    "\n",
    "    for i_feature in range(n_multival_features):\n",
    "        sampling_func = np.vectorize(lambda i_cl:\n",
    "                            sample_multival_once(iterations=iterations,\n",
    "                                base_chance=base_chances[i_cl][i_feature],\n",
    "                                conditional_probabilities=cluster_p_dicts[i_cl][i_feature],\n",
    "                                random_generator=random_generator\n",
    "                            )\n",
    "                        )\n",
    "        output_columns.append(sampling_func(cluster_assignment_vector))\n",
    "\n",
    "    multi_df = pd.DataFrame(np.array(output_columns).T)\n",
    "\n",
    "    colnames = []\n",
    "    for col in multi_df.columns:\n",
    "        colnames.append(f\"multi_{col}\")\n",
    "    \n",
    "    multi_df.columns = colnames\n",
    "\n",
    "    return multi_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>multi_0</th>\n",
       "      <th>multi_1</th>\n",
       "      <th>multi_2</th>\n",
       "      <th>multi_3</th>\n",
       "      <th>multi_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{0, 1, 3}</td>\n",
       "      <td>{0, 1, 4}</td>\n",
       "      <td>{0, 1}</td>\n",
       "      <td>{0, 1}</td>\n",
       "      <td>{0, 1, 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{0, 1, 2}</td>\n",
       "      <td>{0, 1, 4, 5}</td>\n",
       "      <td>{0, 1, 2}</td>\n",
       "      <td>{0, 1, 4, 5}</td>\n",
       "      <td>{0, 1, 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{0, 1, 3}</td>\n",
       "      <td>{0, 1}</td>\n",
       "      <td>{0, 1}</td>\n",
       "      <td>{0, 1}</td>\n",
       "      <td>{0, 4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{2, 3, 5}</td>\n",
       "      <td>{2, 3}</td>\n",
       "      <td>{2, 3}</td>\n",
       "      <td>{0, 1, 2, 3}</td>\n",
       "      <td>{2, 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{2, 3}</td>\n",
       "      <td>{1, 2, 3}</td>\n",
       "      <td>{2, 3, 5}</td>\n",
       "      <td>{0, 2, 3, 5}</td>\n",
       "      <td>{0, 2, 3, 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{2, 3}</td>\n",
       "      <td>{2, 3}</td>\n",
       "      <td>{0, 1, 2, 3}</td>\n",
       "      <td>{2, 3}</td>\n",
       "      <td>{2, 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{2, 3, 4, 5}</td>\n",
       "      <td>{4, 5}</td>\n",
       "      <td>{4, 5}</td>\n",
       "      <td>{4, 5}</td>\n",
       "      <td>{4, 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{2, 4, 5}</td>\n",
       "      <td>{2, 4, 5}</td>\n",
       "      <td>{1, 4, 5, 6}</td>\n",
       "      <td>{0, 2, 4, 6}</td>\n",
       "      <td>{4, 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{4, 5}</td>\n",
       "      <td>{4, 5}</td>\n",
       "      <td>{4, 5}</td>\n",
       "      <td>{0, 1, 2, 3, 4}</td>\n",
       "      <td>{1, 4, 5, 6}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        multi_0       multi_1       multi_2          multi_3       multi_4\n",
       "0     {0, 1, 3}     {0, 1, 4}        {0, 1}           {0, 1}     {0, 1, 2}\n",
       "1     {0, 1, 2}  {0, 1, 4, 5}     {0, 1, 2}     {0, 1, 4, 5}     {0, 1, 3}\n",
       "2     {0, 1, 3}        {0, 1}        {0, 1}           {0, 1}        {0, 4}\n",
       "3     {2, 3, 5}        {2, 3}        {2, 3}     {0, 1, 2, 3}        {2, 3}\n",
       "4        {2, 3}     {1, 2, 3}     {2, 3, 5}     {0, 2, 3, 5}  {0, 2, 3, 5}\n",
       "5        {2, 3}        {2, 3}  {0, 1, 2, 3}           {2, 3}        {2, 3}\n",
       "6  {2, 3, 4, 5}        {4, 5}        {4, 5}           {4, 5}        {4, 5}\n",
       "7     {2, 4, 5}     {2, 4, 5}  {1, 4, 5, 6}     {0, 2, 4, 6}        {4, 5}\n",
       "8        {4, 5}        {4, 5}        {4, 5}  {0, 1, 2, 3, 4}  {1, 4, 5, 6}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_cols = multival_generation(cluster_assignment_vector=[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
    "                    n_clusters=sample_configuration['n_clusters'],\n",
    "                    n_multival_features=sample_configuration['n_multival_features'],\n",
    "                    base_chances=sample_configuration['base_chances'],\n",
    "                    conditional_probabilities=sample_configuration['conditional_probabilities'],\n",
    "                    iterations=4,\n",
    "                    random_generator=np.random.default_rng(42))\n",
    "\n",
    "out_cols"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ExtendedKproto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
